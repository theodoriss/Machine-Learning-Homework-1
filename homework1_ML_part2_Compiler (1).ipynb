{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Downloads\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\Theo\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data= pd.DataFrame.from_csv('ML_HW1_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instructions</th>\n",
       "      <th>optimizer</th>\n",
       "      <th>compiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>push push push test je mov mov mov call mov mo...</td>\n",
       "      <td>L</td>\n",
       "      <td>gcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xor cmp mov seta cmovae ret</td>\n",
       "      <td>H</td>\n",
       "      <td>gcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mov add mov call mov movzx mov call test je mo...</td>\n",
       "      <td>L</td>\n",
       "      <td>gcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>push mov push mov sub test mov jne test jne te...</td>\n",
       "      <td>H</td>\n",
       "      <td>gcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>push sub mov mov mov mov mov mov mov mov mov m...</td>\n",
       "      <td>L</td>\n",
       "      <td>gcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        instructions optimizer compiler\n",
       "0  push push push test je mov mov mov call mov mo...         L      gcc\n",
       "1                        xor cmp mov seta cmovae ret         H      gcc\n",
       "2  mov add mov call mov movzx mov call test je mo...         L      gcc\n",
       "3  push mov push mov sub test mov jne test jne te...         H      gcc\n",
       "4  push sub mov mov mov mov mov mov mov mov mov m...         L      gcc"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(ngram_range=(5,7),analyzer='word') # multivariate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = HashingVectorizer(ngram_range=(3,9),analyzer='word') # multivariate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = vectorizer.fit_transform(data.instructions)\n",
    "y_all = data.compiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 1048576)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import random_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer = random_projection.SparseRandomProjection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_new=transformer.fit_transform(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 8836)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try a logistic regression for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "          test_size=0.2, random_state=1453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= LogisticRegression(multi_class='multinomial',solver='newton-cg').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1623  233  103]\n",
      " [ 151 1701  144]\n",
      " [ 153  176 1716]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clang       0.84      0.83      0.84      1959\n",
      "         gcc       0.81      0.85      0.83      1996\n",
      "         icc       0.87      0.84      0.86      2045\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      6000\n",
      "   macro avg       0.84      0.84      0.84      6000\n",
      "weighted avg       0.84      0.84      0.84      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82802803 0.83503504 0.83513514 0.83023023 0.83363363]\n",
      "Accuracy: 0.832 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.333, random_state=120)\n",
    "scores = cross_val_score(model, X_all, y_all, cv=cv)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = DecisionTreeClassifier().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1379  358  222]\n",
      " [ 247 1536  213]\n",
      " [ 285  336 1424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clang       0.72      0.70      0.71      1959\n",
      "         gcc       0.69      0.77      0.73      1996\n",
      "         icc       0.77      0.70      0.73      2045\n",
      "\n",
      "   micro avg       0.72      0.72      0.72      6000\n",
      "   macro avg       0.73      0.72      0.72      6000\n",
      "weighted avg       0.73      0.72      0.72      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model0.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71051051 0.71261261 0.71191191 0.70740741 0.71531532]\n",
      "Accuracy: 0.712 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.333, random_state=120)\n",
    "scores = cross_val_score(model0, X_all, y_all, cv=cv)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a linear svm classification, one over all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1=svm.SVC(gamma='scale',kernel='linear',cache_size=4000,decision_function_shape='ovo').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1652  213   94]\n",
      " [ 155 1710  131]\n",
      " [ 147  147 1751]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clang       0.85      0.84      0.84      1959\n",
      "         gcc       0.83      0.86      0.84      1996\n",
      "         icc       0.89      0.86      0.87      2045\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      6000\n",
      "   macro avg       0.85      0.85      0.85      6000\n",
      "weighted avg       0.85      0.85      0.85      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = svm.LinearSVC().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1691  179   89]\n",
      " [ 130 1755  111]\n",
      " [ 112  114 1819]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clang       0.87      0.86      0.87      1959\n",
      "         gcc       0.86      0.88      0.87      1996\n",
      "         icc       0.90      0.89      0.90      2045\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6000\n",
      "   macro avg       0.88      0.88      0.88      6000\n",
      "weighted avg       0.88      0.88      0.88      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred,labels=['clang','gcc','icc']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try a random forest classifier,compiled of 100 decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=RandomForestClassifier(n_estimators=100,n_jobs=4).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1644  244   71]\n",
      " [ 189 1688  119]\n",
      " [ 250  185 1610]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clang       0.79      0.84      0.81      1959\n",
      "         gcc       0.80      0.85      0.82      1996\n",
      "         icc       0.89      0.79      0.84      2045\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      6000\n",
      "   macro avg       0.83      0.82      0.82      6000\n",
      "weighted avg       0.83      0.82      0.82      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred,labels=['clang','gcc','icc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81281281 0.82162162 0.81851852 0.81621622 0.81371371]\n",
      "Accuracy: 0.817 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.333, random_state=120)\n",
    "scores = cross_val_score(model3, X_all, y_all, cv=cv)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naive bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(ngram_range=(5,7),analyzer='word',non_negative=True) # multivariate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_all = vectorizer.fit_transform(data.instructions)\n",
    "y_all = data.compiler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "          test_size=0.2, random_state=1453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = MultinomialNB(fit_prior=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1641  188  130]\n",
      " [ 239 1572  185]\n",
      " [ 188  102 1755]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clang       0.79      0.84      0.81      1959\n",
      "         gcc       0.84      0.79      0.81      1996\n",
      "         icc       0.85      0.86      0.85      2045\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      6000\n",
      "   macro avg       0.83      0.83      0.83      6000\n",
      "weighted avg       0.83      0.83      0.83      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model4.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81861862 0.82412412 0.82672673 0.82692693 0.82562563]\n",
      "Accuracy: 0.824 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = ShuffleSplit(n_splits=5, test_size=0.333, random_state=120)\n",
    "scores = cross_val_score(model4, X_all, y_all, cv=cv)\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a grid search on naive bayes hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_values = {'fit_prior': ['True', 'False'],'alpha':[0.001,0.01,0.1,1,5,10]}\n",
    "grid_acc = GridSearchCV(model4, param_grid = grid_values,scoring = 'accuracy',cv=5,iid=False,n_jobs=4).fit(X_all,y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0] params: {'alpha': 0.001, 'fit_prior': 'True'}  \tscore: 0.882 +/- 0.005\n",
      "[ 1] params: {'alpha': 0.001, 'fit_prior': 'False'}  \tscore: 0.882 +/- 0.005\n",
      "[ 2] params: {'alpha': 0.01, 'fit_prior': 'True'}  \tscore: 0.884 +/- 0.004\n",
      "[ 3] params: {'alpha': 0.01, 'fit_prior': 'False'}  \tscore: 0.884 +/- 0.004\n",
      "[ 4] params: {'alpha': 0.1, 'fit_prior': 'True'}  \tscore: 0.872 +/- 0.005\n",
      "[ 5] params: {'alpha': 0.1, 'fit_prior': 'False'}  \tscore: 0.872 +/- 0.005\n",
      "[ 6] params: {'alpha': 1, 'fit_prior': 'True'}  \tscore: 0.830 +/- 0.003\n",
      "[ 7] params: {'alpha': 1, 'fit_prior': 'False'}  \tscore: 0.830 +/- 0.003\n",
      "[ 8] params: {'alpha': 5, 'fit_prior': 'True'}  \tscore: 0.769 +/- 0.003\n",
      "[ 9] params: {'alpha': 5, 'fit_prior': 'False'}  \tscore: 0.769 +/- 0.003\n",
      "[10] params: {'alpha': 10, 'fit_prior': 'True'}  \tscore: 0.732 +/- 0.003\n",
      "[11] params: {'alpha': 10, 'fit_prior': 'False'}  \tscore: 0.732 +/- 0.003\n",
      "Best configuration [2] {'alpha': 0.01, 'fit_prior': 'True'}  0.884\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(grid_acc.cv_results_['params'])):\n",
    "    print(\"[%2d] params: %s  \\tscore: %.3f +/- %.3f\" %(i,\n",
    "        grid_acc.cv_results_['params'][i],\n",
    "        grid_acc.cv_results_['mean_test_score'][i],\n",
    "        grid_acc.cv_results_['std_test_score'][i] ))\n",
    "\n",
    "a = np.argmax(grid_acc.cv_results_['mean_test_score'])\n",
    "bestparams = grid_acc.cv_results_['params'][a]\n",
    "bestscore = grid_acc.cv_results_['mean_test_score'][a]\n",
    "\n",
    "print(\"Best configuration [%d] %r  %.3f\" %(a,bestparams,bestscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = MultinomialNB(fit_prior=True,alpha=0.01).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1716  167   76]\n",
      " [ 147 1758   91]\n",
      " [ 124  107 1814]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       clang       0.86      0.88      0.87      1959\n",
      "         gcc       0.87      0.88      0.87      1996\n",
      "         icc       0.92      0.89      0.90      2045\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      6000\n",
      "   macro avg       0.88      0.88      0.88      6000\n",
      "weighted avg       0.88      0.88      0.88      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model5.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the optimizer for the blind test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_2(name_of_file):\n",
    "    dictionary=dict()\n",
    "    with open(name_of_file,\"r\") as data:\n",
    "        for number,line in enumerate(data):\n",
    "            instructions=[]\n",
    "            instr= line.strip('{\"instructions\": [').split(\"],\")[0].replace('\"','')\n",
    "            for i in range(len(instr.split(', '))):\n",
    "                try:\n",
    "                    instructions.append(instr.split(', ')[i].split()[0])\n",
    "\n",
    "                except:\n",
    "                    print('error or instance  '+str(i)+ 'and number  '+str(number)+ 'with text:   '+ str(instr.split(', ')[i].split()))\n",
    "\n",
    "           \n",
    "\n",
    "            dictionary[number]=[' '.join(instructions).strip(']}')]\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test= pd.DataFrame.from_dict(create_table_2(\"test_dataset_blind.jsonl\"),orient='index',columns=['instructions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>push push push push push push sub mov mov mov ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mov mov mov xor call nop mov call nop test jne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mov neg shr mov ret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>push push mov push push mov sub mov call test ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>est jne mov lea mov mov mov mov call mov mov m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        instructions\n",
       "0  push push push push push push sub mov mov mov ...\n",
       "1  mov mov mov xor call nop mov call nop test jne...\n",
       "2                                mov neg shr mov ret\n",
       "3  push push mov push push mov sub mov call test ...\n",
       "4  est jne mov lea mov mov mov mov call mov mov m..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_all_test = vectorizer.fit_transform(data_test.instructions) # the vectorizer of naive bayes with non negative values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler_predictions = model5.predict(X_all_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "982"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(compiler_predictions=='clang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1014"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(compiler_predictions=='gcc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1004"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(compiler_predictions=='icc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gcc', 'gcc', 'clang', ..., 'gcc', 'clang', 'clang'], dtype='<U5')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiler_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"ML_HW1_compilers_predictions.csv\", compiler_predictions,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
