{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Downloads\n"
     ]
    }
   ],
   "source": [
    "cd \"C:\\Users\\Theo\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(name_of_file):\n",
    "    dictionary=dict()\n",
    "    with open(name_of_file,\"r\") as data:\n",
    "        for number,line in enumerate(data):\n",
    "            instructions=[]\n",
    "            instr= line.strip('{\"instructions\": [').split(\"],\")[0].replace('\"','')\n",
    "            for i in range(len(instr.split(', '))):\n",
    "                try:\n",
    "                    instructions.append(instr.split(', ')[i].split()[0])\n",
    "\n",
    "                except:\n",
    "                    print('error or instance  '+str(i)+ 'and number  '+str(number)+ 'with text:   '+ str(instr.split(', ')[i].split()))\n",
    "\n",
    "            rest= line.strip('{\"instructions\": [').split(\"],\")[1].replace('\"','').replace('}','').replace(',','').split()\n",
    "                #print(rest[1]) # number 1 is the optimizer and number 3 is the compiler\n",
    "            optimizer = rest[1]\n",
    "            compiler=rest[3]\n",
    "\n",
    "            dictionary[number]=[' '.join(instructions),rest[1],rest[3]]\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.DataFrame.from_dict(create_table(\"train_dataset.jsonl\"),orient='index',columns=['instructions','optimizer','compiler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'ML_HW1_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: from_csv is deprecated. Please use read_csv(...) instead. Note that some of the default arguments are different, so please refer to the documentation for from_csv when changing your function calls\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data= pd.DataFrame.from_csv('ML_HW1_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17924"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['optimizer']=='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5974666666666667"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data['optimizer']=='L')/30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer(ngram_range=(5,7),analyzer='word') # multivariate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = vectorizer.fit_transform(data.instructions)\n",
    "y_all = data.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "          test_size=0.2, random_state=1453)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model1= LogisticRegression().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1669  713]\n",
      " [ 324 3294]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.84      0.70      0.76      2382\n",
      "           L       0.82      0.91      0.86      3618\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      6000\n",
      "   macro avg       0.83      0.81      0.81      6000\n",
      "weighted avg       0.83      0.83      0.82      6000\n",
      "\n",
      "accuracy is:  0.8271666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy is:  '+str((confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[1][1])/(confusion_matrix(y_test, y_pred)[0].sum()+confusion_matrix(y_test, y_pred)[1].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.81843593 0.82562407 0.82590307 0.81744557 0.82199161]\n",
      "Weighted f1 score : 0.822 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5,random_state=120,shuffle=True)\n",
    "scores = cross_val_score(model1, X_all, y_all, cv=cv,scoring='f1_weighted')\n",
    "print(scores)\n",
    "print(\"Weighted f1 score : %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "grid_values = {'penalty': ['l1', 'l2'],'C':[0.01,.09,0.1,1,5,10,25,50,100]}\n",
    "grid_acc = GridSearchCV(model1, param_grid = grid_values,scoring = 'f1_weighted',cv=cv,iid=False,n_jobs=4).fit(X_all,y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0] params: {'C': 0.01, 'penalty': 'l1'}  \tscore: 0.493 +/- 0.002\n",
      "[ 1] params: {'C': 0.01, 'penalty': 'l2'}  \tscore: 0.602 +/- 0.001\n",
      "[ 2] params: {'C': 0.09, 'penalty': 'l1'}  \tscore: 0.683 +/- 0.004\n",
      "[ 3] params: {'C': 0.09, 'penalty': 'l2'}  \tscore: 0.731 +/- 0.003\n",
      "[ 4] params: {'C': 0.1, 'penalty': 'l1'}  \tscore: 0.688 +/- 0.004\n",
      "[ 5] params: {'C': 0.1, 'penalty': 'l2'}  \tscore: 0.735 +/- 0.002\n",
      "[ 6] params: {'C': 1, 'penalty': 'l1'}  \tscore: 0.797 +/- 0.003\n",
      "[ 7] params: {'C': 1, 'penalty': 'l2'}  \tscore: 0.822 +/- 0.004\n",
      "[ 8] params: {'C': 5, 'penalty': 'l1'}  \tscore: 0.836 +/- 0.003\n",
      "[ 9] params: {'C': 5, 'penalty': 'l2'}  \tscore: 0.847 +/- 0.003\n",
      "[10] params: {'C': 10, 'penalty': 'l1'}  \tscore: 0.842 +/- 0.004\n",
      "[11] params: {'C': 10, 'penalty': 'l2'}  \tscore: 0.851 +/- 0.003\n",
      "[12] params: {'C': 25, 'penalty': 'l1'}  \tscore: 0.844 +/- 0.006\n",
      "[13] params: {'C': 25, 'penalty': 'l2'}  \tscore: 0.854 +/- 0.004\n",
      "[14] params: {'C': 50, 'penalty': 'l1'}  \tscore: 0.843 +/- 0.006\n",
      "[15] params: {'C': 50, 'penalty': 'l2'}  \tscore: 0.855 +/- 0.005\n",
      "[16] params: {'C': 100, 'penalty': 'l1'}  \tscore: 0.842 +/- 0.006\n",
      "[17] params: {'C': 100, 'penalty': 'l2'}  \tscore: 0.856 +/- 0.004\n",
      "Best configuration [17] {'C': 100, 'penalty': 'l2'}  0.856\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(grid_acc.cv_results_['params'])):\n",
    "    print(\"[%2d] params: %s  \\tscore: %.3f +/- %.3f\" %(i,\n",
    "        grid_acc.cv_results_['params'][i],\n",
    "        grid_acc.cv_results_['mean_test_score'][i],\n",
    "        grid_acc.cv_results_['std_test_score'][i] ))\n",
    "\n",
    "a = np.argmax(grid_acc.cv_results_['mean_test_score'])\n",
    "bestparams = grid_acc.cv_results_['params'][a]\n",
    "bestscore = grid_acc.cv_results_['mean_test_score'][a]\n",
    "\n",
    "print(\"Best configuration [%d] %r  %.3f\" %(a,bestparams,bestscore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model15= LogisticRegression(C=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1893  489]\n",
      " [ 369 3249]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.84      0.79      0.82      2382\n",
      "           L       0.87      0.90      0.88      3618\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      6000\n",
      "   macro avg       0.85      0.85      0.85      6000\n",
      "weighted avg       0.86      0.86      0.86      6000\n",
      "\n",
      "accuracy is:  0.857\n"
     ]
    }
   ],
   "source": [
    "y_pred = model15.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy is:  '+str((confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[1][1])/(confusion_matrix(y_test, y_pred)[0].sum()+confusion_matrix(y_test, y_pred)[1].sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try a linear support vector machines model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=svm.SVC(gamma='scale',kernel='linear',cache_size=40000).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1796  586]\n",
      " [ 322 3296]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.85      0.75      0.80      2382\n",
      "           L       0.85      0.91      0.88      3618\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      6000\n",
      "   macro avg       0.85      0.83      0.84      6000\n",
      "weighted avg       0.85      0.85      0.85      6000\n",
      "\n",
      "accuracy is:  0.8486666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy is:  '+str((confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[1][1])/(confusion_matrix(y_test, y_pred)[0].sum()+confusion_matrix(y_test, y_pred)[1].sum())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try 2 decision trees, with different loss criteria classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1674  708]\n",
      " [ 517 3101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.76      0.70      0.73      2382\n",
      "           L       0.81      0.86      0.84      3618\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      6000\n",
      "   macro avg       0.79      0.78      0.78      6000\n",
      "weighted avg       0.79      0.80      0.79      6000\n",
      "\n",
      "accuracy is:  0.7958333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = model3.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy is:  '+str((confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[1][1])/(confusion_matrix(y_test, y_pred)[0].sum()+confusion_matrix(y_test, y_pred)[1].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79525905 0.79573074 0.78594184 0.78101215 0.78833776]\n",
      "Weighted f1 score : 0.789 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5,random_state=120,shuffle=True)\n",
    "scores = cross_val_score(model3, X_all, y_all, cv=cv,scoring='f1_weighted')\n",
    "print(scores)\n",
    "print(\"Weighted f1 score : %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = DecisionTreeClassifier(criterion='entropy').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1665  717]\n",
      " [ 553 3065]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.75      0.70      0.72      2382\n",
      "           L       0.81      0.85      0.83      3618\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      6000\n",
      "   macro avg       0.78      0.77      0.78      6000\n",
      "weighted avg       0.79      0.79      0.79      6000\n",
      "\n",
      "accuracy is:  0.7883333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = model4.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy is:  '+str((confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[1][1])/(confusion_matrix(y_test, y_pred)[0].sum()+confusion_matrix(y_test, y_pred)[1].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.78845018 0.78975191 0.78833334 0.77928151 0.79065298]\n",
      "Weighted f1 score : 0.787 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5,random_state=120,shuffle=True)\n",
    "scores = cross_val_score(model4, X_all, y_all, cv=cv,scoring='f1_weighted')\n",
    "print(scores)\n",
    "print(\"Weighted f1 score : %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try a random forest, consisting of 100 decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5=RandomForestClassifier(n_estimators=100).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1699  683]\n",
      " [ 350 3268]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.83      0.71      0.77      2382\n",
      "           L       0.83      0.90      0.86      3618\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      6000\n",
      "   macro avg       0.83      0.81      0.82      6000\n",
      "weighted avg       0.83      0.83      0.83      6000\n",
      "\n",
      "accuracy is:  0.8278333333333333\n"
     ]
    }
   ],
   "source": [
    "y_pred = model5.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy is:  '+str((confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[1][1])/(confusion_matrix(y_test, y_pred)[0].sum()+confusion_matrix(y_test, y_pred)[1].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82408336 0.83428923 0.8379738  0.81980556 0.82318422]\n",
      "Weighted f1 score : 0.828 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5,random_state=120,shuffle=True)\n",
    "scores = cross_val_score(model5, X_all, y_all, cv=cv,scoring='f1_weighted')\n",
    "print(scores)\n",
    "print(\"Weighted f1 score : %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### if the compilers affect the optimization. the last part of stratified, which is with compiler icc? seems to have many H, so the score is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### the problem is the low recall of the High optimization. with grid search, logistic regression smv too, seem to solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a knn classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = KNeighborsClassifier(n_neighbors=10,weights='distance').fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1372 1010]\n",
      " [1054 2564]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.57      0.58      0.57      2382\n",
      "           L       0.72      0.71      0.71      3618\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      6000\n",
      "   macro avg       0.64      0.64      0.64      6000\n",
      "weighted avg       0.66      0.66      0.66      6000\n",
      "\n",
      "accuracy is:  0.656\n"
     ]
    }
   ],
   "source": [
    "y_pred = model6.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy is:  '+str((confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[1][1])/(confusion_matrix(y_test, y_pred)[0].sum()+confusion_matrix(y_test, y_pred)[1].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66388183 0.65808142 0.66698607 0.6598116  0.66063526]\n",
      "Weighted f1 score : 0.662 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5,random_state=120,shuffle=True)\n",
    "scores = cross_val_score(model6, X_all, y_all, cv=cv,scoring='f1_weighted')\n",
    "print(scores)\n",
    "print(\"Weighted f1 score : %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try a naive bayes multinomial classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n",
      "C:\\Users\\Theo\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\hashing.py:102: DeprecationWarning: the option non_negative=True has been deprecated in 0.19 and will be removed in version 0.21.\n",
      "  \" in version 0.21.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = HashingVectorizer(ngram_range=(5,7),analyzer='word',non_negative=True) # non negative values are changed, so we can implement bayes\n",
    "X_all = vectorizer.fit_transform(data.instructions)\n",
    "y_all = data.optimizer\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, \n",
    "          test_size=0.2, random_state=1453)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = MultinomialNB(fit_prior=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1402  980]\n",
      " [ 305 3313]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           H       0.82      0.59      0.69      2382\n",
      "           L       0.77      0.92      0.84      3618\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      6000\n",
      "   macro avg       0.80      0.75      0.76      6000\n",
      "weighted avg       0.79      0.79      0.78      6000\n",
      "\n",
      "accuracy is:  0.7858333333333334\n"
     ]
    }
   ],
   "source": [
    "y_pred = model7.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('accuracy is:  '+str((confusion_matrix(y_test, y_pred)[0][0]+confusion_matrix(y_test, y_pred)[1][1])/(confusion_matrix(y_test, y_pred)[0].sum()+confusion_matrix(y_test, y_pred)[1].sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77139745 0.78008472 0.78310348 0.7770984  0.76437526]\n",
      "Weighted f1 score : 0.775 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5,random_state=120,shuffle=True)\n",
    "scores = cross_val_score(model7, X_all, y_all, cv=cv,scoring='f1_weighted')\n",
    "print(scores)\n",
    "print(\"Weighted f1 score : %0.3f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the optimizer for the blind test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_2(name_of_file):\n",
    "    dictionary=dict()\n",
    "    with open(name_of_file,\"r\") as data:\n",
    "        for number,line in enumerate(data):\n",
    "            instructions=[]\n",
    "            instr= line.strip('{\"instructions\": [').split(\"],\")[0].replace('\"','')\n",
    "            for i in range(len(instr.split(', '))):\n",
    "                try:\n",
    "                    instructions.append(instr.split(', ')[i].split()[0])\n",
    "\n",
    "                except:\n",
    "                    print('error or instance  '+str(i)+ 'and number  '+str(number)+ 'with text:   '+ str(instr.split(', ')[i].split()))\n",
    "\n",
    "           \n",
    "\n",
    "            dictionary[number]=[' '.join(instructions).strip(']}')]\n",
    "    return dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test= pd.DataFrame.from_dict(create_table_2(\"test_dataset_blind.jsonl\"),orient='index',columns=['instructions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>push push push push push push sub mov mov mov ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mov mov mov xor call nop mov call nop test jne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mov neg shr mov ret</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>push push mov push push mov sub mov call test ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>est jne mov lea mov mov mov mov call mov mov m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        instructions\n",
       "0  push push push push push push sub mov mov mov ...\n",
       "1  mov mov mov xor call nop mov call nop test jne...\n",
       "2                                mov neg shr mov ret\n",
       "3  push push mov push push mov sub mov call test ...\n",
       "4  est jne mov lea mov mov mov mov call mov mov m..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_test = vectorizer.fit_transform(data_test.instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_predictions = model15.predict(X_all_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['L', 'H', 'L', ..., 'L', 'H', 'L'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1196"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(optimizer_predictions=='H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1804"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(optimizer_predictions=='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"ML_HW1_optimizers_predictions.csv\", optimizer_predictions,fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
